{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZAbxj1SPAdRp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.models as models\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "\n",
        "class LazyRotationImageDataset(Dataset):\n",
        "\tdef __init__(self, root_dir, transform=None):\n",
        "\t\tsuper(LazyRotationImageDataset, self).__init__()\n",
        "\t\tself.data = [os.path.join(root_dir, f) for f in os.listdir(root_dir) if f.endswith(\".jpg\")]\n",
        "\t\tself.rotations = [0, 90, 180, 270]\n",
        "\t\tself.transform = transform\n",
        "\n",
        "\tdef __len__(self):\n",
        "\t\treturn len(self.data)\n",
        "\n",
        "\tdef __getitem__(self, idx):\n",
        "\t\timg_path = self.data[idx]\n",
        "\t\timage = Image.open(img_path)\n",
        "\n",
        "\t\tif self.transform:\n",
        "\t\t\timage = self.transform(image)\n",
        "\n",
        "\t\trotation_idx = torch.randint(0, 4, (1,)).item()  # Random index for rotation\n",
        "\t\trotation_angle = self.rotations[rotation_idx]  # Corresponding rotation angle\n",
        "\n",
        "\t\trotation_transform = transforms.Compose([\n",
        "\t\t\ttransforms.RandomRotation([rotation_angle, rotation_angle], expand=True),\n",
        "\t\t\ttransforms.ToTensor()\n",
        "\t\t])\n",
        "\n",
        "\t\trotated_image = rotation_transform(image)  # Applies the selected rotation\n",
        "\t\treturn rotated_image, rotation_idx\n",
        "\n",
        "# Example usage\n",
        "dataset = LazyRotationImageDataset(\"../data/images\")\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Now you can use this dataloader in your training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rYWb-GT8_h9i"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3000"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZzrCeCoAvHi",
        "outputId": "3fb0455a-b234-4cc1-b789-58ded05be624"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# Model modification to predict rotation\n",
        "class RotationPredictor(nn.Module):\n",
        "\tdef __init__(self):\n",
        "\t\tsuper().__init__()\n",
        "\t\tself.resnet = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
        "\t\tself.resnet.fc = nn.Linear(self.resnet.fc.in_features, 4)  # Predicting 4 rotation classes\n",
        "\n",
        "\tdef forward(self, x):\n",
        "\t\treturn self.resnet(x)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = RotationPredictor().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "# model.train()\n",
        "# epochs = 10\n",
        "# for epoch in range(epochs):\n",
        "#   for images, labels in tqdm(dataloader):\n",
        "#     images = images.to(device)\n",
        "#     labels = labels.to(device)\n",
        "#     outputs = model(images)\n",
        "#     loss = criterion(outputs, labels)\n",
        "#     optimizer.zero_grad()\n",
        "#     loss.backward()\n",
        "#     optimizer.step()\n",
        "#   print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss.item()}\")\n",
        "\n",
        "# Now the model is fine-tuned to predict rotations, which also improves its feature extraction capability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"model_finetuned.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LiWhVFHX_kTq"
      },
      "outputs": [],
      "source": [
        "def count_parameters(model):\n",
        "\treturn sum(p.numel() for p in model.parameters())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2n-8fa7P_4Iq",
        "outputId": "f058a423-b504-4fa0-8a12-54ab38709203"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "11178564"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_parameters(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1PoLfcW7393",
        "outputId": "07a68d11-c699-4e95-8d60-efb25a23fa8c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(683072, 683072)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.eval()\n",
        "import copy\n",
        "\n",
        "resnet_pretrained = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
        "resnet_pretrained = nn.Sequential(*list(resnet_pretrained.children())[:-4], nn.AdaptiveAvgPool2d((1, 1)))\n",
        "resnet_pretrained = torch.quantization.quantize_dynamic(\n",
        "\tresnet_pretrained, {nn.Linear, nn.Conv2d}, dtype=torch.qint8\n",
        ")\n",
        "\n",
        "\n",
        "model_finetunned = copy.deepcopy(model.resnet)\n",
        "model_finetunned = nn.Sequential(*list(model_finetunned.children())[:-4], nn.AdaptiveAvgPool2d((1, 1)))\n",
        "model_finetunned = torch.quantization.quantize_dynamic(\n",
        "\tmodel_finetunned, {nn.Linear, nn.Conv2d}, dtype=torch.qint8\n",
        ")\n",
        "\n",
        "count_parameters(resnet_pretrained), count_parameters(model_finetunned)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(resnet_pretrained.state_dict(), \"model_pretrained.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "features_pretrained = torch.empty((len(dataset), 128))\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "94it [01:04,  1.45it/s]\n"
          ]
        }
      ],
      "source": [
        "for i, (images, labels) in tqdm(enumerate(dataloader)):\n",
        "\toutputs = resnet_pretrained(images).squeeze().detach()\n",
        "\tfeatures_pretrained[i * batch_size: i * batch_size + len(images)] = outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(features_pretrained, \"features_pretrained.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "94it [00:05, 17.52it/s]\n"
          ]
        }
      ],
      "source": [
        "features_finetuned = torch.empty((len(dataset), 128)).to(device)\n",
        "batch_size = 32\n",
        "\n",
        "for i, (images, labels) in tqdm(enumerate(dataloader)):\n",
        "\timages = images.to(device)\n",
        "\tlabels = labels.to(device)\n",
        "\toutputs = model_finetunned(images).squeeze().detach()\n",
        "\tfeatures_finetuned[i * batch_size: i * batch_size + len(images)] = outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(features_finetuned, \"features_finetuned.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "w_pretrained = torch.load(\"../models/model_pretrained.pt\")\n",
        "features_pretrained = torch.load(\"../data/features_pretrained.pt\")\n",
        "w_finetuned = torch.load(\"../models/model_finetuned.pt\")\n",
        "features_finetuned = torch.load(\"../data/features_finetuned.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "base_resnet = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
        "model_pretrained = nn.Sequential(\n",
        "    *(list(base_resnet.children())[:-4]),\n",
        "    nn.AdaptiveAvgPool2d((1, 1))\n",
        ")\n",
        "model_pretrained.load_state_dict(w_pretrained)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# base_resnet = RotationPredictor().resnet\n",
        "# model_finetuned = nn.Sequential(\n",
        "#     *(list(base_resnet.children())[:-4]),\n",
        "#     nn.AdaptiveAvgPool2d((1, 1))\n",
        "# )\n",
        "# model_finetuned.load_state_dict(w_finetuned)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/eric/miniconda3/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/home/eric/miniconda3/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "\n",
        "kmeans_finetuned = KMeans(n_clusters=5, random_state=0)\n",
        "clusters_finetuned = kmeans_finetuned.fit_predict(features_finetuned.cpu().numpy())\n",
        "kmeans_pretrained = KMeans(n_clusters=5, random_state=0)\n",
        "clusters_pretrained = kmeans_pretrained.fit_predict(features_pretrained.cpu().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/eric/miniconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/home/eric/miniconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "import copy\n",
        "\n",
        "resnet_original = models.resnet18(pretrained=False)\n",
        "model_test_pretrained = nn.Sequential(*list(resnet_original.children())[:-4], nn.AdaptiveAvgPool2d((1, 1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the saved model weights\n",
        "model_weights_path = '../models/model_pretrained.pt'\n",
        "model_test_pretrained.load_state_dict(torch.load(model_weights_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (2): ReLU(inplace=True)\n",
              "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (5): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (6): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              ")"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_test_pretrained.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class LazyImageDataset(Dataset):\n",
        "\tdef __init__(self, root_dir, transform=None):\n",
        "\t\tsuper(LazyImageDataset, self).__init__()\n",
        "\t\tself.data = [os.path.join(root_dir, f) for f in os.listdir(root_dir) if f.endswith(\".jpg\")]\n",
        "\t\tself.transform = transform\n",
        "\n",
        "\tdef __len__(self):\n",
        "\t\treturn len(self.data)\n",
        "\n",
        "\tdef __getitem__(self, idx):\n",
        "\t\timg_path = self.data[idx]\n",
        "\t\timage = Image.open(img_path)\n",
        "\n",
        "\t\tif self.transform:\n",
        "\t\t\timage = self.transform(image)\n",
        "\n",
        "\t\treturn image\n",
        "\n",
        "test_dataset = LazyImageDataset('../data/images_test', transform=transforms.ToTensor())\n",
        "test_data_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "1it [00:00,  1.71it/s]\n"
          ]
        }
      ],
      "source": [
        "model_test_pretrained.eval()  # Ensure the model is in evaluation mode\n",
        "\n",
        "batch_size = 32\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model_test_pretrained = model_test_pretrained.to(device)\n",
        "test_embs = torch.empty((len(test_dataset), 128)).to(device)\n",
        "\n",
        "for i, images in tqdm(enumerate(test_data_loader)):\n",
        "\timages = images.to(device)\n",
        "\toutputs = model_test_pretrained(images).squeeze().detach()\n",
        "\ttest_embs[i * batch_size: i * batch_size + len(images)] = outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([10, 128])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_embs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 0, 3, 1, 1, 0, 1, 0, 0, 0], dtype=int32)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clusters = kmeans_pretrained.predict(test_embs.cpu().numpy())\n",
        "clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([3, 128])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "idx = 4\n",
        "same_cluster = np.where(clusters == clusters[idx])[0]\n",
        "cluster_embs = test_embs[same_cluster]\n",
        "cluster_embs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([3, 3])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# compute similarity_matrix\n",
        "vectors = cluster_embs / cluster_embs.norm(dim=1, keepdim=True)  # normalize the vectors\n",
        "similarity_matrix = vectors @ vectors.t() \n",
        "similarity_matrix.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([3])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "similarities = similarity_matrix.mean(dim=1)\n",
        "similarities.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_clusters(embs, kmeans):\n",
        "\treturn kmeans.predict(embs.cpu().numpy())\n",
        "\n",
        "def get_cluster_embs(embs, clusters, idx):\n",
        "\tsame_cluster = np.where(clusters == clusters[idx])[0]\n",
        "\treturn embs[same_cluster]\n",
        "\n",
        "def get_similarity_embs(embs):\n",
        "\tvectors = embs / embs.norm(dim=1, keepdim=True)\n",
        "\tsimilarity_matrix = vectors @ vectors.t()\n",
        "\treturn similarity_matrix.mean(dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "\n",
        "images_dir = \"data/images\"\n",
        "\n",
        "images = [os.path.join(images_dir, file) for file in os.listdir(images_dir) if file.endswith(\".jpg\")]\n",
        "\n",
        "def images_to_show(img):\n",
        "\t\n",
        "\treturn img, img, img\n",
        "\n",
        "def set_as_input(img):\n",
        "    blank = np.ones_like(img)*255\n",
        "    return img, blank, blank, blank\n",
        "\n",
        "with gr.Blocks() as gui:\n",
        "  with gr.Row():\n",
        "    with gr.Column(scale=2):\n",
        "      img_in = gr.Image(type=\"numpy\")\n",
        "      btn = gr.Button(\"Search\")\n",
        "    with gr.Column(scale=1):\n",
        "      img_out1 = gr.Image(show_download_button=False, interactive=False, type=\"numpy\")\n",
        "      btn1 = gr.Button(\"Set as input\")\n",
        "      img_out2 = gr.Image(show_download_button=False, interactive=False, type=\"numpy\")\n",
        "      btn2 = gr.Button(\"Set as input\")\n",
        "      img_out3 = gr.Image(show_download_button=False, interactive=False, type=\"numpy\")\n",
        "      btn3 = gr.Button(\"Set as input\")\n",
        "  \n",
        "  btn.click(images_to_show, inputs=img_in, outputs=[img_out1, img_out2, img_out3])\n",
        "  btn1.click(set_as_input, inputs=img_out1, outputs=[img_in, img_out1, img_out2, img_out3])\n",
        "  btn2.click(set_as_input, inputs=img_out2, outputs=[img_in, img_out1, img_out2, img_out3])\n",
        "  btn3.click(set_as_input, inputs=img_out3, outputs=[img_in, img_out1, img_out2, img_out3])\n",
        "\n",
        "gui.launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fine tunning model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/eric/miniconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/home/eric/miniconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "import copy\n",
        "\n",
        "# Load the original pre-trained ResNet model\n",
        "resnet_original = models.resnet18(weights=None)  # Make sure to use the correct ResNet model (resnet18, resnet50, etc.)\n",
        "\n",
        "\n",
        "# Modify the model by removing the last four layers and adding an AdaptiveAvgPool2d\n",
        "model_test_finetunning = nn.Sequential(*list(resnet_original.children())[:-4], nn.AdaptiveAvgPool2d((1, 1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "_IncompatibleKeys(missing_keys=['0.weight', '1.weight', '1.bias', '1.running_mean', '1.running_var', '4.0.conv1.weight', '4.0.bn1.weight', '4.0.bn1.bias', '4.0.bn1.running_mean', '4.0.bn1.running_var', '4.0.conv2.weight', '4.0.bn2.weight', '4.0.bn2.bias', '4.0.bn2.running_mean', '4.0.bn2.running_var', '4.1.conv1.weight', '4.1.bn1.weight', '4.1.bn1.bias', '4.1.bn1.running_mean', '4.1.bn1.running_var', '4.1.conv2.weight', '4.1.bn2.weight', '4.1.bn2.bias', '4.1.bn2.running_mean', '4.1.bn2.running_var', '5.0.conv1.weight', '5.0.bn1.weight', '5.0.bn1.bias', '5.0.bn1.running_mean', '5.0.bn1.running_var', '5.0.conv2.weight', '5.0.bn2.weight', '5.0.bn2.bias', '5.0.bn2.running_mean', '5.0.bn2.running_var', '5.0.downsample.0.weight', '5.0.downsample.1.weight', '5.0.downsample.1.bias', '5.0.downsample.1.running_mean', '5.0.downsample.1.running_var', '5.1.conv1.weight', '5.1.bn1.weight', '5.1.bn1.bias', '5.1.bn1.running_mean', '5.1.bn1.running_var', '5.1.conv2.weight', '5.1.bn2.weight', '5.1.bn2.bias', '5.1.bn2.running_mean', '5.1.bn2.running_var'], unexpected_keys=['resnet.conv1.weight', 'resnet.bn1.weight', 'resnet.bn1.bias', 'resnet.bn1.running_mean', 'resnet.bn1.running_var', 'resnet.bn1.num_batches_tracked', 'resnet.layer1.0.conv1.weight', 'resnet.layer1.0.bn1.weight', 'resnet.layer1.0.bn1.bias', 'resnet.layer1.0.bn1.running_mean', 'resnet.layer1.0.bn1.running_var', 'resnet.layer1.0.bn1.num_batches_tracked', 'resnet.layer1.0.conv2.weight', 'resnet.layer1.0.bn2.weight', 'resnet.layer1.0.bn2.bias', 'resnet.layer1.0.bn2.running_mean', 'resnet.layer1.0.bn2.running_var', 'resnet.layer1.0.bn2.num_batches_tracked', 'resnet.layer1.1.conv1.weight', 'resnet.layer1.1.bn1.weight', 'resnet.layer1.1.bn1.bias', 'resnet.layer1.1.bn1.running_mean', 'resnet.layer1.1.bn1.running_var', 'resnet.layer1.1.bn1.num_batches_tracked', 'resnet.layer1.1.conv2.weight', 'resnet.layer1.1.bn2.weight', 'resnet.layer1.1.bn2.bias', 'resnet.layer1.1.bn2.running_mean', 'resnet.layer1.1.bn2.running_var', 'resnet.layer1.1.bn2.num_batches_tracked', 'resnet.layer2.0.conv1.weight', 'resnet.layer2.0.bn1.weight', 'resnet.layer2.0.bn1.bias', 'resnet.layer2.0.bn1.running_mean', 'resnet.layer2.0.bn1.running_var', 'resnet.layer2.0.bn1.num_batches_tracked', 'resnet.layer2.0.conv2.weight', 'resnet.layer2.0.bn2.weight', 'resnet.layer2.0.bn2.bias', 'resnet.layer2.0.bn2.running_mean', 'resnet.layer2.0.bn2.running_var', 'resnet.layer2.0.bn2.num_batches_tracked', 'resnet.layer2.0.downsample.0.weight', 'resnet.layer2.0.downsample.1.weight', 'resnet.layer2.0.downsample.1.bias', 'resnet.layer2.0.downsample.1.running_mean', 'resnet.layer2.0.downsample.1.running_var', 'resnet.layer2.0.downsample.1.num_batches_tracked', 'resnet.layer2.1.conv1.weight', 'resnet.layer2.1.bn1.weight', 'resnet.layer2.1.bn1.bias', 'resnet.layer2.1.bn1.running_mean', 'resnet.layer2.1.bn1.running_var', 'resnet.layer2.1.bn1.num_batches_tracked', 'resnet.layer2.1.conv2.weight', 'resnet.layer2.1.bn2.weight', 'resnet.layer2.1.bn2.bias', 'resnet.layer2.1.bn2.running_mean', 'resnet.layer2.1.bn2.running_var', 'resnet.layer2.1.bn2.num_batches_tracked', 'resnet.layer3.0.conv1.weight', 'resnet.layer3.0.bn1.weight', 'resnet.layer3.0.bn1.bias', 'resnet.layer3.0.bn1.running_mean', 'resnet.layer3.0.bn1.running_var', 'resnet.layer3.0.bn1.num_batches_tracked', 'resnet.layer3.0.conv2.weight', 'resnet.layer3.0.bn2.weight', 'resnet.layer3.0.bn2.bias', 'resnet.layer3.0.bn2.running_mean', 'resnet.layer3.0.bn2.running_var', 'resnet.layer3.0.bn2.num_batches_tracked', 'resnet.layer3.0.downsample.0.weight', 'resnet.layer3.0.downsample.1.weight', 'resnet.layer3.0.downsample.1.bias', 'resnet.layer3.0.downsample.1.running_mean', 'resnet.layer3.0.downsample.1.running_var', 'resnet.layer3.0.downsample.1.num_batches_tracked', 'resnet.layer3.1.conv1.weight', 'resnet.layer3.1.bn1.weight', 'resnet.layer3.1.bn1.bias', 'resnet.layer3.1.bn1.running_mean', 'resnet.layer3.1.bn1.running_var', 'resnet.layer3.1.bn1.num_batches_tracked', 'resnet.layer3.1.conv2.weight', 'resnet.layer3.1.bn2.weight', 'resnet.layer3.1.bn2.bias', 'resnet.layer3.1.bn2.running_mean', 'resnet.layer3.1.bn2.running_var', 'resnet.layer3.1.bn2.num_batches_tracked', 'resnet.layer4.0.conv1.weight', 'resnet.layer4.0.bn1.weight', 'resnet.layer4.0.bn1.bias', 'resnet.layer4.0.bn1.running_mean', 'resnet.layer4.0.bn1.running_var', 'resnet.layer4.0.bn1.num_batches_tracked', 'resnet.layer4.0.conv2.weight', 'resnet.layer4.0.bn2.weight', 'resnet.layer4.0.bn2.bias', 'resnet.layer4.0.bn2.running_mean', 'resnet.layer4.0.bn2.running_var', 'resnet.layer4.0.bn2.num_batches_tracked', 'resnet.layer4.0.downsample.0.weight', 'resnet.layer4.0.downsample.1.weight', 'resnet.layer4.0.downsample.1.bias', 'resnet.layer4.0.downsample.1.running_mean', 'resnet.layer4.0.downsample.1.running_var', 'resnet.layer4.0.downsample.1.num_batches_tracked', 'resnet.layer4.1.conv1.weight', 'resnet.layer4.1.bn1.weight', 'resnet.layer4.1.bn1.bias', 'resnet.layer4.1.bn1.running_mean', 'resnet.layer4.1.bn1.running_var', 'resnet.layer4.1.bn1.num_batches_tracked', 'resnet.layer4.1.conv2.weight', 'resnet.layer4.1.bn2.weight', 'resnet.layer4.1.bn2.bias', 'resnet.layer4.1.bn2.running_mean', 'resnet.layer4.1.bn2.running_var', 'resnet.layer4.1.bn2.num_batches_tracked', 'resnet.fc.weight', 'resnet.fc.bias'])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the saved model weights\n",
        "model_weights_path = '../models/model_finetuned.pt'\n",
        "model_test_finetunning.load_state_dict(torch.load(model_weights_path), strict=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (2): ReLU(inplace=True)\n",
              "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (5): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (6): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              ")"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_test_finetunning.eval()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
