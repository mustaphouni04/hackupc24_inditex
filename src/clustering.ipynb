{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assuming we have a matrix of the embeded feature vectors:\n",
    "embeddings=np.array()\n",
    "\n",
    "# Assuming 'embeddings' is a 2D array where each row represents the embedded feature vector of an image\n",
    "# 'eps' is the epsilon parameter, 'min_samples' is the min_samples parameter\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=5, metric='euclidean')\n",
    "clusters = dbscan.fit_predict(embeddings)\n",
    "\n",
    "# 'clusters' will contain the cluster assignments for each data point (-1 for noise/outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering visualitzation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'embeddings' is a 2D array where each row represents the embedded feature vector of an image\n",
    "# 'clusters' contains the cluster assignments obtained from DBSCAN\n",
    "\n",
    "# Reduce dimensionality to 2D using t-SNE\n",
    "tsne = TSNE(n_components=2)\n",
    "embeddings_2d = tsne.fit_transform(embeddings)\n",
    "\n",
    "# Plot the data points, color-coded by cluster assignment\n",
    "plt.figure(figsize=(8, 6))\n",
    "for cluster_label in set(clusters):\n",
    "    if cluster_label == -1:\n",
    "        # Plot noise points in black\n",
    "        plt.scatter(embeddings_2d[clusters == cluster_label, 0], embeddings_2d[clusters == cluster_label, 1], color='black', label='Noise')\n",
    "    else:\n",
    "        plt.scatter(embeddings_2d[clusters == cluster_label, 0], embeddings_2d[clusters == cluster_label, 1], label=f'Cluster {cluster_label}')\n",
    "plt.title('DBSCAN Clustering Visualization with t-SNE')\n",
    "plt.xlabel('t-SNE Dimension 1')\n",
    "plt.ylabel('t-SNE Dimension 2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute similarities within cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'embeddings' is a 2D array where each row represents the embedded feature vector of an image\n",
    "# 'clusters' contains the cluster assignments obtained from DBSCAN\n",
    "\n",
    "# Compute pairwise cosine similarities within each cluster\n",
    "similarities_within_clusters = []\n",
    "for cluster_label in set(clusters):\n",
    "    cluster_indices = (clusters == cluster_label)\n",
    "    cluster_embeddings = embeddings[cluster_indices]\n",
    "    pairwise_similarities = cosine_similarity(cluster_embeddings)\n",
    "    similarities_within_clusters.append(pairwise_similarities)\n",
    "\n",
    "# 'similarities_within_clusters' will contain pairwise similarities within each cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 10 similar images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Assuming 'embeddings_with_links' is a 2D numpy array where each row contains the embedded feature vector of an image and its corresponding link\n",
    "# 'specific_image_index' is the index of the specific image for which you want to find similar images\n",
    "# 'k' is the number of similar images to retrieve\n",
    "\n",
    "def top_k_similar_images(embeddings_with_links, specific_image_index, k=10):\n",
    "    # Extract the embedded feature vector of the specific image\n",
    "    specific_embedding = embeddings_with_links[specific_image_index, 0].reshape(1, -1)\n",
    "\n",
    "    # Compute cosine similarities between the specific image and all other images\n",
    "    similarities = cosine_similarity(specific_embedding, embeddings_with_links[:, 0])\n",
    "\n",
    "    # Sort indices of images based on similarity (excluding the specific image itself)\n",
    "    similar_image_indices = np.argsort(-similarities)[0][1:k+1]\n",
    "\n",
    "    # Retrieve links of top k similar images\n",
    "    similar_image_links = embeddings_with_links[similar_image_indices, 1]\n",
    "\n",
    "    return similar_image_links.tolist()\n",
    "\n",
    "# Example usage:\n",
    "# Replace 'embeddings_with_links' and 'specific_image_index' with your actual data\n",
    "# Replace 'k' with the desired number of similar images\n",
    "similar_images = top_k_similar_images(embeddings_with_links, specific_image_index=0, k=10)\n",
    "print(\"Top 10 similar images:\")\n",
    "for idx, link in enumerate(similar_images, start=1):\n",
    "    print(f\"{idx}. {link}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
